defmodule EventasaurusDiscovery.Sources.Waw4Free.DetailExtractor do
  @moduledoc # 
  Extracts event details from waw4free.pl event detail pages.

  Parses HTML to extract:
  - Title (h1)
  - Date and time (Polish date formats)
  - Venue (address and district)
  - Description (paragraphs)
  - Categories (Polish category links)
  - Image URL
  - Voluntary donation indicator

  require Logger
  alias EventasaurusDiscovery.Sources.Waw4Free.Config
  alias EventasaurusDiscovery.Sources.Shared.Parsers.MultilingualDateParser

  Extract event details from event page HTML.
  Returns event data map or error tuple.
  def extract_event_from_html(html, url) when is_binary(html) and is_binary(url) do
    case Floki.parse_document(html) do
      {:ok, document} ->
        # Check for error page or missing content
        if is_error_page?(document) do
          Logger.warning("⚠️ Error page detected for URL: #{url}")
          {:error, :not_found}
        else
          extract_event_details(document, url)
        end

      {:error, reason} ->
        Logger.error("Failed to parse HTML for #{url}: #{inspect(reason)}")
        {:error, :parse_failed}
    end
  end

  defp is_error_page?(document) do
    # Check for common error indicators
    title = Floki.find(document, "h1") |> Floki.text() |> String.downcase()

    String.contains?(title, "błąd") ||
      String.contains?(title, "nie znaleziono") ||
      String.contains?(title, "error") ||
      String.contains?(title, "404")
  end

  defp extract_event_details(document, url) do
    try do
      # Extract basic fields
      title = extract_title(document)
      description = extract_description(document)
      image_url = extract_image(document)

      # Extract date/time with Polish parser
      date_text = extract_date_text(document)
      time_text = extract_time_text(document)
      combined_date_text = combine_date_time_text(date_text, time_text)

      # Parse dates using Polish date parser
      date_result = parse_polish_date(combined_date_text)

      # Extract venue information
      venue = extract_venue(document)
      district = extract_district(document)

      # Extract categories (Polish)
      categories = extract_categories(document)

      # Check for voluntary donation
      is_free = check_voluntary_donation(document, description)

      # Build event data
      event_data = %{
        title: title,
        description: description,
        image_url: image_url,
        venue: venue,
        district: district,
        categories: categories,
        is_free: is_free,
        source_url: url,
        external_id: Config.extract_external_id(url),
        raw_date_text: combined_date_text
      }

      # Merge date parsing results
      event_data = case date_result do
        {:ok, %{starts_at: starts_at} = dates} ->
          event_data
          |> Map.put(:starts_at, starts_at)
          |> Map.put(:ends_at, Map.get(dates, :ends_at))

        {:error, reason} ->
          Logger.warning("Failed to parse date '#{combined_date_text}': #{inspect(reason)}")
          event_data
      end

      # Validate required fields
      if valid_event?(event_data) do
        {:ok, event_data}
      else
        Logger.warning("Invalid event data for #{url}: missing required fields")
        {:error, :invalid_data}
      end
    rescue
      e ->
        Logger.error("Failed to extract event details from #{url}: #{inspect(e)}")
        {:error, :extraction_failed}
    end
  end

  # Extract title from h1 element.
  defp extract_title(document) do
    document
    |> Floki.find("h1")
    |> Floki.text()
    |> String.trim()
    |> clean_text()
  end

  # Extract description from paragraphs.
  defp extract_description(document) do
    # Try main content area first
    description =
      document
      |> Floki.find(".content, .opis, .description, article p")
      |> Enum.map(&Floki.text/1)
      |> Enum.map(&String.trim/1)
      |> Enum.reject(&(&1 == ""))
      |> Enum.join("\n\n")

    # Fallback to all paragraphs if no content found
    if String.length(description) < 20 do
      document
      |> Floki.find("p")
      |> Enum.map(&Floki.text/1)
      |> Enum.map(&String.trim/1)
      |> Enum.reject(&(&1 == ""))
      |> Enum.take(5)  # Limit to first 5 paragraphs
      |> Enum.join("\n\n")
      |> clean_text()
    else
      clean_text(description)
    end
  end

  # Extract date text from document.
  # Looks for patterns like "📅 Data: wtorek, 28 października 2025"
  defp extract_date_text(document) do
    # Try specific date selectors
    selectors = [
      ".kiedy",           # Common Polish selector
      ".data",
      ".date",
      "[class*='date']",
      "[class*='data']"
    ]

    date_text =
      Enum.find_value(selectors, fn selector ->
        text = document |> Floki.find(selector) |> Floki.text() |> String.trim()
        if String.length(text) > 0, do: text, else: nil
      end)

    # Fallback: search for text containing "Data:"
    date_text || find_text_containing(document, ["Data:", "📅"])
  end

  # Extract time text from document.
  # Looks for patterns like "⌚ Godzina rozpoczęcia: 18:00"
  defp extract_time_text(document) do
    # Try specific time selectors
    selectors = [
      ".godzina",
      ".time",
      "[class*='time']",
      "[class*='godzina']"
    ]

    time_text =
      Enum.find_value(selectors, fn selector ->
        text = document |> Floki.find(selector) |> Floki.text() |> String.trim()
        if String.length(text) > 0, do: text, else: nil
      end)

    # Fallback: search for text containing "Godzina:"
    time_text || find_text_containing(document, ["Godzina:", "⌚"])
  end

  Combine date and time text for parsing.
  defp combine_date_time_text(date_text, time_text) do
    cond do
      date_text && time_text -> "#{date_text} #{time_text}"
      date_text -> date_text
      time_text -> time_text
      true -> ""
    end
  end

  Parse Polish date using MultilingualDateParser.
  defp parse_polish_date(text) when is_binary(text) and byte_size(text) > 0 do
    MultilingualDateParser.extract_and_parse(text,
      languages: [:polish],
      timezone: "Europe/Warsaw"
    )
  end

  defp parse_polish_date(_), do: {:error, :no_date_text}

  Extract venue information.
  Looks for patterns like "📌 Miejsce: Warszawa - Śródmieście, ul. Złota 11"
  defp extract_venue(document) do
    # Try specific venue selectors
    selectors = [
      ".gdzie",           # Common Polish selector
      ".miejsce",
      ".venue",
      ".location",
      "[class*='venue']",
      "[class*='miejsce']"
    ]

    venue_text =
      Enum.find_value(selectors, fn selector ->
        text = document |> Floki.find(selector) |> Floki.text() |> String.trim()
        if String.length(text) > 0, do: text, else: nil
      end)

    # Fallback: search for text containing "Miejsce:"
    venue_text = venue_text || find_text_containing(document, ["Miejsce:", "📌"])

    # Clean up venue text
    if venue_text do
      venue_text
      |> String.replace(~r/^.*Miejsce:\s*/i, "")
      |> String.replace("📌", "")
      |> String.trim()
      |> clean_text()
    else
      nil
    end
  end

  Extract district from venue text or district links.
  defp extract_district(document) do
    # Try district links
    district_links = Floki.find(document, "a[href*='dzielnica'], a[href*='district']")

    if Enum.any?(district_links) do
      district_links
      |> List.first()
      |> Floki.text()
      |> String.trim()
    else
      # Try to extract from venue text
      venue = extract_venue(document)
      if venue && String.contains?(venue, " - ") do
        venue
        |> String.split(" - ")
        |> Enum.at(1)
        |> case do
          nil -> nil
          text -> text |> String.split(",") |> List.first() |> String.trim()
        end
      else
        nil
      end
    end
  end

  Extract categories from category links.
  Returns list of Polish category slugs.
  defp extract_categories(document) do
    document
    |> Floki.find("a[href*='kategoria'], a[href*='category'], .kategoria a, .categories a")
    |> Enum.map(&Floki.text/1)
    |> Enum.map(&String.trim/1)
    |> Enum.map(&String.downcase/1)
    |> Enum.reject(&(&1 == ""))
    |> Enum.uniq()
  end

  Extract image URL from document.
  defp extract_image(document) do
    # Try main image selectors
    image =
      Floki.find(document, ".event-image img, .featured-image img, article img, .content img")
      |> List.first()

    case image do
      nil ->
        nil

      img ->
        # Try src, data-src, data-lazy-src attributes
        src =
          Floki.attribute(img, "src") |> List.first() ||
          Floki.attribute(img, "data-src") |> List.first() ||
          Floki.attribute(img, "data-lazy-src") |> List.first()

        if src && !String.starts_with?(src, "data:") do
          build_full_url(src)
        else
          nil
        end
    end
  end

  Check if event has voluntary donation indicator.
  defp check_voluntary_donation(document, description) do
    text = Floki.text(document) |> String.downcase()
    desc = String.downcase(description || "")

    String.contains?(text, "dobrowolna zrzutka") ||
      String.contains?(desc, "dobrowolna zrzutka") ||
      String.contains?(text, "wstęp wolny") ||
      String.contains?(desc, "wstęp wolny")
  end

  # Helper functions

  defp find_text_containing(document, search_terms) do
    document
    |> Floki.text()
    |> String.split("\n")
    |> Enum.find(fn line ->
      Enum.any?(search_terms, &String.contains?(line, &1))
    end)
    |> case do
      nil -> nil
      line -> String.trim(line)
    end
  end

  defp clean_text(text) when is_binary(text) do
    text
    |> String.replace(~r/\s+/, " ")
    |> String.trim()
  end

  defp clean_text(nil), do: nil

  defp build_full_url(url) when is_binary(url) do
    cond do
      String.starts_with?(url, "http://") or String.starts_with?(url, "https://") ->
        url

      String.starts_with?(url, "//") ->
        "https:" <> url

      String.starts_with?(url, "/") ->
        Config.base_url() <> url

      true ->
        Config.base_url() <> "/" <> url
    end
  end

  defp valid_event?(event_data) do
    # Required fields
    has_title = event_data[:title] && String.length(event_data.title) > 3
    has_url = event_data[:source_url] != nil
    has_external_id = event_data[:external_id] != nil

    has_title && has_url && has_external_id
  end
end
